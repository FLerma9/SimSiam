{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import neptune.new as neptune\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import simsiam.loader\n",
    "from simsiam.builder import SimSiam\n",
    "from simsiam.criterion import SimSiamLoss\n",
    "from simsiam.validation import KNNValidation\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2b7c3",
   "metadata": {},
   "source": [
    "Hiper-parámetros a definir por el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57676068",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'mobilenet_v2' #Opciones: resnet34, mobilenet_v2, alexnet, vgg13 y squeezenet1_1\n",
    "dataset = 'ImageWoof' #Nombre del dataset\n",
    "train_path = 'ImageWoof/train' #Path del dataset con las imágenes de train\n",
    "val_path = 'ImageWoof/val' #Path del dataset con las imágenes de val\n",
    "model_path = 'simsiam/Unsupervised_Training_Checkpoints/ImageWoof/Mobilenet/' #Path donde se querrá guardar el modelo\n",
    "batch_size = 32\n",
    "epochs = 800 #Número de épocas\n",
    "lr = 0.05 #Learning rate base\n",
    "weight_decay = 0.0001\n",
    "momentum = 0.9\n",
    "gpu = 0 #Número de la gpu donde ejecutar la red\n",
    "nombre = 'ImageWoofSimSiamMobilenetV2_800epochs' #Nombre del experimento\n",
    "eval_freq = 5 #Frecuencia con la que validar con el clasificador kNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7823d4d",
   "metadata": {},
   "source": [
    "Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a862f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, init_lr, epoch, n_epochs):\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / n_epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        images[0] = images[0].cuda(0, non_blocking=True)\n",
    "        images[1] = images[1].cuda(0, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        z1, z2, p1, p2 = model(x1=images[0], x2=images[1])\n",
    "        loss = criterion(z1, z2, p1, p2)\n",
    "        losses.update(loss.item(), images[0].size(0))\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if i % 30 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "     transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "     transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "     transforms.RandomGrayscale(p=0.2),\n",
    "     transforms.RandomApply([simsiam.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.ImageFolder(train_path, simsiam.loader.TwoCropsTransform(transform_train))\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimSiam(arch)\n",
    "init_lr = lr*batch_size / 256\n",
    "optim_params = [{'params': model.encoder.parameters(), 'fix_lr': False},\n",
    "                {'params': model.predictor.parameters(), 'fix_lr': True}]\n",
    "optimizer = optim.SGD(optim_params, init_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = SimSiamLoss()\n",
    "if gpu is not None:\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model = model.cuda(gpu)\n",
    "    criterion = criterion.cuda(gpu)\n",
    "    cudnn.benchmark = True\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "best_acc = 0.0\n",
    "validation = KNNValidation(batch_size, train_path, val_path, model)\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "    train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    if (epoch+1) % eval_freq == 0:\n",
    "        print(\"Validando...\")\n",
    "        val_top1_acc = validation.eval()\n",
    "        print('Top1: {}'.format(val_top1_acc))\n",
    "        # guardamos el mejor modelo\n",
    "        if val_top1_acc > best_acc:\n",
    "            best_acc = val_top1_acc\n",
    "            name = 'best.pth'\n",
    "            torch.save(model, model_path + name)\n",
    "        name = 'checkpoint_{}.pth'.format(epoch+1)\n",
    "        torch.save(model, model_path + name)\n",
    "print('Mejor accuracy:', best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0b495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
